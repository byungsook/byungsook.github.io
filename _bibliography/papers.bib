@article{yang2022implicit,
author = {Yang, Lingchen and Kim, Byungsoo and Zoss, Gaspard and G\"{o}zc\"{u}, Baran and Gross, Markus and Solenthaler, Barbara},
title = {Implicit Neural Representation for Physics-Driven Actuated Soft Bodies},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3528223.3530156},
doi = {10.1145/3528223.3530156},
abstract = {Active soft bodies can affect their shape through an internal actuation mechanism that induces a deformation. Similar to recent work, this paper utilizes a differentiable, quasi-static, and physics-based simulation layer to optimize for actuation signals parameterized by neural networks. Our key contribution is a general and implicit formulation to control active soft bodies by defining a function that enables a continuous mapping from a spatial point in the material space to the actuation value. This property allows us to capture the signal's dominant frequencies, making the method discretization agnostic and widely applicable. We extend our implicit model to mandible kinematics for the particular case of facial animation and show that we can reliably reproduce facial expressions captured with high-quality capture systems. We apply the method to volumetric soft bodies, human poses, and facial expressions, demonstrating artist-friendly properties, such as simple control over the latent space and resolution invariance at test time.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {122},
numpages = {10},
keywords = {differentiable physics, digital human, deep learning},
abbr={SIGGRAPH},
conference={Proc. SIGGRAPH},
note = {Honorable Mention},
website = {https://studios.disneyresearch.com/2022/07/24/implicit-neural-representation-for-physics-driven-actuated-soft-bodies/},
pdf = {https://studios.disneyresearch.com/app/uploads/2022/07/Implicit_Neural_Representation_for_Physics-driven_Actuated_Soft_Bodies_final-1.pdf},
supp = {https://studios.disneyresearch.com/app/uploads/2022/08/Implicit_Neural_Representation_for_Physics-driven_Actuated_Soft_Bodies_supplemental.pdf},
preview={https://studios.disneyresearch.com/app/uploads/2022/07/Implicit_Neural_Representation_for_Physics-driven_Actuated_Soft_Bodies.jpg},
video={https://www.youtube.com/watch?v=9EERe_CTazk},
selected={true}
}

@article{kim2022sketch,
author = {Kim, Byungsoo and Huang, Xingchang and Wuelfroth, Laura and Tang, Jingwei and Cordonnier, Guillaume and Gross, Markus and Solenthaler, Barbara},
title = {Deep Reconstruction of 3D Smoke Densities from Artist Sketches},
journal = {Computer Graphics Forum},
volume = {41},
number = {2},
pages = {97-110},
keywords = {CCS Concepts, • Computing methodologies → Shape modeling, Neural networks},
doi = {https://doi.org/10.1111/cgf.14461},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14461},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14461},
abstract = {Abstract Creative processes of artists often start with hand-drawn sketches illustrating an object. Pre-visualizing these keyframes is especially challenging when applied to volumetric materials such as smoke. The authored 3D density volumes must capture realistic flow details and turbulent structures, which is highly non-trivial and remains a manual and time-consuming process. We therefore present a method to compute a 3D smoke density field directly from 2D artist sketches, bridging the gap between early-stage prototyping of smoke keyframes and pre-visualization. From the sketch inputs, we compute an initial volume estimate and optimize the density iteratively with an updater CNN. Our differentiable sketcher is embedded into the end-to-end training, which results in robust reconstructions. Our training data set and sketch augmentation strategy are designed such that it enables general applicability. We evaluate the method on synthetic inputs and sketches from artists depicting both realistic smoke volumes and highly non-physical smoke shapes. The high computational performance and robustness of our method at test time allows interactive authoring sessions of volumetric density fields for rapid prototyping of ideas by novice users.},
year = {2022},
month = {may},
abbr={EUROGRAPHICS},
conference={Proc. EUROGRAPHICS},
pdf = {https://cgl.ethz.ch/Downloads/Publications/Papers/2022/Kim22a/Kim22a.pdf},
supp = {https://cgl.ethz.ch/Downloads/Publications/Papers/2022/Kim22a/Kim22a_supp.pdf},
code = {https://github.com/byungsook/sketch2fluid},
preview={sketchden.jpg},
video={https://www.youtube.com/watch?v=PF7QqNZ28hk},
slides={sketchden.pdf},
selected={true}
}

@article{jouvet2022igm,
title={Deep Learning Speeds Up Ice Flow Modelling by Several Orders of Magnitude},
volume={68},
DOI={10.1017/jog.2021.120},
number={270},
journal={Journal of Glaciology},
publisher={Cambridge University Press},
author={Jouvet, Guillaume and Cordonnier, Guillaume and Kim, Byungsoo and Lüthi, Martin and Vieli, Andreas and Aschwanden, Andy},
abstract={This paper introduces the Instructed Glacier Model (IGM) – a model that simulates ice dynamics, mass balance and its coupling to predict the evolution of glaciers, icefields or ice sheets. The novelty of IGM is that it models the ice flow by a Convolutional Neural Network, which is trained from data generated with hybrid SIA + SSA or Stokes ice flow models. By doing so, the most computationally demanding model component is substituted by a cheap emulator. Once trained with representative data, we demonstrate that IGM permits to model mountain glaciers up to 1000 × faster than Stokes ones on Central Processing Units (CPU) with fidelity levels above 90% in terms of ice flow solutions leading to nearly identical transient thickness evolution. Switching to the GPU often permits additional significant speed-ups, especially when emulating Stokes dynamics or/and modelling at high spatial resolution. IGM is an open-source Python code which deals with two-dimensional (2-D) gridded input and output data. Together with a companion library of trained ice flow emulators, IGM permits user-friendly, highly efficient and mechanically state-of-the-art glacier and icefields simulations.},
year={2021},
month={dec},
pages={651–664},
url={https://doi.org/10.1017/jog.2021.120},
preview={iceflow.jpg},
selected={true}
}

@ARTICLE{Charreyron2021emns,
author={Charreyron, Samuel L. and Boehler, Quentin and Kim, Byungsoo and Weibel, Cameron and Chautems, Christophe and Nelson, Bradley J.},
journal={IEEE Transactions on Robotics},
title={Modeling Electromagnetic Navigation Systems},
abstract={Remote magnetic navigation is used for the manipulation of untethered micro and nanorobots, as well as tethered magnetic surgical tools for minimally invasive medicine. Mathematical modeling of the magnetic fields generated by magnetic navigation systems is a fundamental task in the control of such tools for biomedical applications. In this article, we describe and compare several existing and newly developed methods for representations of continuous magnetic fields using interpolation in the context of remote magnetic navigation. Clinical-scale electromagnetic navigation systems feature nonlinear magnetization and magnetization interactions between electromagnets, which renders accurate magnetic field modeling challenging. We first introduce a method that can adapt existing linear models to correct for nonlinear magnetization, with similar performance to the current state-of-the-art nonlinear model. Furthermore, we present a method based on convolutional neural networks.},
year={2021},
month={jan},
volume={37},
number={4},
pages={1009-1021},
doi={10.1109/TRO.2020.3047053},
url={https://doi.org/10.1109/TRO.2020.3047053},
abbr={T-RO},
selected={true}
}

@thesis{kim2020phdthesis,
copyright = {In Copyright - Non-Commercial Use Permitted},
year = {2020},
author = {Kim, Byungsoo},
size = {178 p.},
language = {en},
address = {Zurich},
publisher = {ETH Zurich},
DOI = {10.3929/ethz-b-000468169},
title = {Data-Driven Methods for Artist-Directed Fluid Simulations},
school = {ETH Zurich},
Note = {Doctoral Thesis},
url={https://doi.org/10.3929/ethz-b-000468169},
preview={phd_thesis.png},
selected={true}
}

@article{wiewel2020latent,
author = {Wiewel, Steffen and Kim, Byungsoo and Azevedo, Vinicius C. and Solenthaler, Barbara and Thuerey, Nils},
title = {Latent Space Subdivision: Stable and Controllable Time Predictions for Fluid Flow},
journal = {Computer Graphics Forum},
volume = {39},
number = {8},
pages = {15-25},
keywords = {CCS Concepts, • Computing methodologies → Neural networks, Physical simulation},
doi = {https://doi.org/10.1111/cgf.14097},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14097},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14097},
abstract = {Abstract We propose an end-to-end trained neural network architecture to robustly predict the complex dynamics of fluid flows with high temporal stability. We focus on single-phase smoke simulations in 2D and 3D based on the incompressible Navier-Stokes (NS) equations, which are relevant for a wide range of practical problems. To achieve stable predictions for long-term flow sequences with linear execution times, a convolutional neural network (CNN) is trained for spatial compression in combination with a temporal prediction network that consists of stacked Long Short-Term Memory (LSTM) layers. Our core contribution is a novel latent space subdivision (LSS) to separate the respective input quantities into individual parts of the encoded latent space domain. As a result, this allows to distinctively alter the encoded quantities without interfering with the remaining latent space values and hence maximizes external control. By selectively overwriting parts of the predicted latent space points, our proposed method is capable to robustly predict long-term sequences of complex physics problems, like the flow of fluids. In addition, we highlight the benefits of a recurrent training on the latent space creation, which is performed by the spatial compression network. Furthermore, we thoroughly evaluate and discuss several different components of our method.},
year = {2020},
month = {nov},
conference = {Proc. SCA},
preview={latent.jpg},
website={https://ge.in.tum.de/publications/2020-lssubdiv-wiewel/},
arxiv = {2003.08723},
selected={true}
}

@article{kim2020lnst,
author = {Kim, Byungsoo and Azevedo, Vinicius C. and Gross, Markus and Solenthaler, Barbara},
title = {Lagrangian Neural Style Transfer for Fluids},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3386569.3392473},
doi = {10.1145/3386569.3392473},
abstract = {Artistically controlling the shape, motion and appearance of fluid simulations pose major challenges in visual effects production. In this paper, we present a neural style transfer approach from images to 3D fluids formulated in a Lagrangian viewpoint. Using particles for style transfer has unique benefits compared to grid-based techniques. Attributes are stored on the particles and hence are trivially transported by the particle motion. This intrinsically ensures temporal consistency of the optimized stylized structure and notably improves the resulting quality. Simultaneously, the expensive, recursive alignment of stylization velocity fields of grid approaches is unnecessary, reducing the computation time to less than an hour and rendering neural flow stylization practical in production settings. Moreover, the Lagrangian representation improves artistic control as it allows for multi-fluid stylization and consistent color transfer from images, and the generality of the method enables stylization of smoke and liquids likewise.},
journal = {ACM Trans. Graph.},
conference = {Proc. SIGGRAPH},
month = {jul},
articleno = {52},
numpages = {10},
keywords = {neural style transfer, physically-based animation, fluid simulation, deep learning},
arxiv = {2005.00803},
preview={lnst.jpg},
video={https://www.youtube.com/watch?v=WPmUsIVf3-4},
code={https://github.com/byungsook/neural-flow-style},
selected={true}
}

@inproceedings {christen2020cnst,
booktitle = {Eurographics 2020 - Short Papers},
editor = {Wilkie, Alexander and Banterle, Francesco},
title = {{Neural Smoke Stylization with Color Transfer}},
author = {Christen, Fabienne and Kim, Byungsoo and Azevedo, Vinicius C. and Solenthaler, Barbara},
abstract={Artistically controlling fluid simulations requires a large amount of manual work by an artist. The recently presented transportbased neural style transfer approach simplifies workflows as it transfers the style of arbitrary input images onto 3D smoke simulations. However, the method only modifies the shape of the fluid but omits color information. In this work, we therefore extend the previous approach to obtain a complete pipeline for transferring shape and color information onto 2D and 3D smoke simulations with neural networks. Our results demonstrate that our method successfully transfers colored style features consistently in space and time to smoke data for different input textures.},
year = {2020},
month = {may},
publisher = {The Eurographics Association},
ISBN = {978-3-03868-101-4},
pages = {49-52},
DOI = {10.2312/egs.20201015},
url = {https://doi.org/10.2312/egs.20201015},
preview={cnst.jpg},
arxiv = {1912.08757},
video={https://www.youtube.com/watch?v=TyNlaBoP6oI},
slides={https://www.youtube.com/watch?v=CwvuaQBnJbA},
selected={true}
}

@inproceedings {biland2020deepfreq,
booktitle = {Eurographics 2020 - Short Papers},
editor = {Wilkie, Alexander and Banterle, Francesco},
title = {{Frequency-Aware Reconstruction of Fluid Simulations with Generative Networks}},
author = {Biland, Simon and Azevedo, Vinicius C. and Kim, Byungsoo and Solenthaler, Barbara},
abstract={Convolutional neural networks were recently employed to fully reconstruct fluid simulation data from a set of reduced parameters. However, since (de-)convolutions traditionally trained with supervised L1-loss functions do not discriminate between low and high frequencies in the data, the error is not minimized efficiently for higher bands. This directly correlates with the quality of the perceived results, since missing high frequency details are easily noticeable. In this paper, we analyze the reconstruction quality of generative networks and present a frequency-aware loss function that is able to focus on specific bands of the dataset during training time. We show that our approach improves reconstruction quality of fluid simulation data in mid-frequency bands, yielding perceptually better results while requiring comparable training time.},
year = {2020},
month = {may},
publisher = {The Eurographics Association},
ISSN = {1017-4656},
ISBN = {978-3-03868-101-4},
DOI = {10.2312/egs.20201019},
url = {https://doi.org/10.2312/egs.20201019},
preview={deepfreq.jpg},
arxiv = {1912.08776},
slides={https://www.youtube.com/watch?v=yR7INFmFLDY&t=180s},
selected={true}
}

@article{kim2019tnst,
author = {Kim, Byungsoo and Azevedo, Vinicius C. and Gross, Markus and Solenthaler, Barbara},
title = {Transport-Based Neural Style Transfer for Smoke Simulations},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3355089.3356560},
doi = {10.1145/3355089.3356560},
abstract = {Artistically controlling fluids has always been a challenging task. Optimization techniques rely on approximating simulation states towards target velocity or density field configurations, which are often handcrafted by artists to indirectly control smoke dynamics. Patch synthesis techniques transfer image textures or simulation features to a target flow field. However, these are either limited to adding structural patterns or augmenting coarse flows with turbulent structures, and hence cannot capture the full spectrum of different styles and semantically complex structures. In this paper, we propose the first Transport-based Neural Style Transfer (TNST) algorithm for volumetric smoke data. Our method is able to transfer features from natural images to smoke simulations, enabling general content-aware manipulations ranging from simple patterns to intricate motifs. The proposed algorithm is physically inspired, since it computes the density transport from a source input smoke to a desired target configuration. Our transport-based approach allows direct control over the divergence of the stylization velocity field by optimizing incompressible and irrotational potentials that transport smoke towards stylization. Temporal consistency is ensured by transporting and aligning subsequent stylized velocities, and 3D reconstructions are computed by seamlessly merging stylizations from different camera viewpoints.},
journal = {ACM Trans. Graph.},
month = {nov},
articleno = {188},
numpages = {11},
keywords = {fluid simulation, physically-based animation, neural style transfer},
conference = {Proc. SIGGRAPH Asia},
arxiv = {1905.07442},
preview={tnst.jpg},
video={https://www.youtube.com/watch?v=67qVRhoOQPE},
code={https://github.com/byungsook/neural-flow-style},
slides={tnst.pdf},
selected={true}
}

@article{kim2019deepvortices,
author = {Kim, Byungsoo and Günther, Tobias},
title = {Robust Reference Frame Extraction from Unsteady 2D Vector Fields with Convolutional Neural Networks},
journal = {Computer Graphics Forum},
volume = {38},
number = {3},
pages = {285-295},
keywords = {CCS Concepts, • Human-centered computing → Scientific visualization, • Computing methodologies → Supervised learning},
doi = {https://doi.org/10.1111/cgf.13689},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13689},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13689},
abstract = {Abstract Robust feature extraction is an integral part of scientific visualization. In unsteady vector field analysis, researchers recently directed their attention towards the computation of near-steady reference frames for vortex extraction, which is a numerically challenging endeavor. In this paper, we utilize a convolutional neural network to combine two steps of the visualization pipeline in an end-to-end manner: the filtering and the feature extraction. We use neural networks for the extraction of a steady reference frame for a given unsteady 2D vector field. By conditioning the neural network to noisy inputs and resampling artifacts, we obtain numerically stabler results than existing optimization-based approaches. Supervised deep learning typically requires a large amount of training data. Thus, our second contribution is the creation of a vector field benchmark data set, which is generally useful for any local deep learning-based feature extraction. Based on Vatistas velocity profile, we formulate a parametric vector field mixture model that we parameterize based on numerically-computed example vector fields in near-steady reference frames. Given the parametric model, we can efficiently synthesize thousands of vector fields that serve as input to our deep learning architecture. The proposed network is evaluated on an unseen numerical fluid flow simulation.},
year = {2019},
month = {jul},
arxiv = {1903.10255},
conference={Proc. EUROVIS},
preview={deepvortices.jpg},
slides={deepvortices.pdf},
selected={true}
}

@article{kim2019deepfluids,
author = {Kim, Byungsoo and Azevedo, Vinicius C. and Thuerey, Nils and Kim, Theodore and Gross, Markus and Solenthaler, Barbara},
title = {Deep Fluids: A Generative Network for Parameterized Fluid Simulations},
journal = {Computer Graphics Forum},
volume = {38},
number = {2},
pages = {59-70},
keywords = {CCS Concepts, • Computing methodologies → Physical simulation, Neural networks},
doi = {https://doi.org/10.1111/cgf.13619},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13619},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13619},
abstract = {Abstract This paper presents a novel generative model to synthesize fluid simulations from a set of reduced parameters. A convolutional neural network is trained on a collection of discrete, parameterizable fluid simulation velocity fields. Due to the capability of deep learning architectures to learn representative features of the data, our generative model is able to accurately approximate the training data set, while providing plausible interpolated in-betweens. The proposed generative model is optimized for fluids by a novel loss function that guarantees divergence-free velocity fields at all times. In addition, we demonstrate that we can handle complex parameterizations in reduced spaces, and advance simulations in time by integrating in the latent space with a second network. Our method models a wide variety of fluid behaviors, thus enabling applications such as fast construction of simulations, interpolation of fluids with different parameters, time re-sampling, latent space simulations, and compression of fluid simulation data. Reconstructed velocity fields are generated up to 700× faster than re-simulating the data with the underlying CPU solver, while achieving compression rates of up to 1300×.},
year = {2019},
month = {jun},
arxiv = {1806.02071},
conference={Proc. EUROGRAPHICS},
code={https://github.com/byungsook/deep-fluids},
video={https://www.youtube.com/watch?v=hSDzOZ9IO8U},
preview={deepfluids.jpg},
slides={deepfluids.pdf},
selected={true}
}

@article{kim2018semantic,
author = {Kim, Byungsoo and Wang, Oliver and Öztireli, A. Cengiz and Gross, Markus},
title = {Semantic Segmentation for Line Drawing Vectorization Using Neural Networks},
journal = {Computer Graphics Forum},
volume = {37},
number = {2},
pages = {329-338},
keywords = {CCS Concepts, •Computing methodologies → Image manipulation, Computational photography},
doi = {https://doi.org/10.1111/cgf.13365},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13365},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13365},
abstract = {Abstract In this work, we present a method to vectorize raster images of line art. Inverting the rasterization procedure is inherently ill-conditioned, as there exist many possible vector images that could yield the same raster image. However, not all of these vector images are equally useful to the user, especially if performing further edits is desired. We therefore define the problem of computing an instance segmentation of the most likely set of paths that could have created the raster image. Once the segmentation is computed, we use existing vectorization approaches to vectorize each path, and then combine all paths into the final output vector image. To determine which set of paths is most likely, we train a pair of neural networks to provide semantic clues that help resolve ambiguities at intersection and overlap regions. These predictions are made considering the full context of the image, and are then globally combined by solving a Markov Random Field (MRF). We demonstrate the flexibility of our method by generating results on character datasets, a synthetic random line dataset, and a dataset composed of human drawn sketches. For all cases, our system accurately recovers paths that adhere to the semantics of the drawings.},
year = {2018},
month = {may},
conference={Proc. EUROGRAPHICS},
code={https://github.com/byungsook/vectornet},
preview={vectornet.jpg},
slides={vectornet.pdf},
pdf={https://cgl.ethz.ch/Downloads/Publications/Papers/2018/Kim18a/Kim18a.pdf},
selected={true}
}

@thesis{kim2016masterthesis,
copyright = {In Copyright - Non-Commercial Use Permitted},
year = {2016},
author = {Kim, Byungsoo},
size = {1 Online-Ressource},
keywords = {NEURONALE NETZWERKE + KONNEKTIONISMUS (KÜNSTLICHE INTELLIGENZ); MASCHINELLES LERNEN (KÜNSTLICHE INTELLIGENZ); BERECHENBARE GEOMETRIE + COMPUTERGEOMETRIE; NEURAL NETWORKS + CONNECTIONISM (ARTIFICIAL INTELLIGENCE); MACHINE LEARNING (ARTIFICIAL INTELLIGENCE); COMPUTATIONAL GEOMETRY + GEOMETRIC COMPUTATIONS},
language = {en},
address = {Zurich},
publisher = {ETH Zurich},
DOI = {10.3929/ethz-a-010807297},
title = {Learning Structured Representations for Geometry},
Note = {Master Thesis},
school = {ETH Zurich},
url={https://doi.org/10.3929/ethz-a-010807297},
preview={master_thesis.png},
selected={true}
}

@thesis{kim2014oldpub,
title={Previous Works},
author={Kim, Byungsoo},
year = {2008 - 2014},
url={https://sites.google.com/site/byungsookim0608},
preview={old_pub.png},
selected={true}
}